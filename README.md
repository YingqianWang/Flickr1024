
# *<center>Flickr1024: A Large-Scale Dataset for Stereo Image Super-Resolution</center>* 

***<center><a href="https://yingqianwang.github.io/homepage" target="_blank">Yingqian Wang</a>&emsp; Longguang Wang&emsp; Jungang Yang&emsp; Wei An&emsp; <a href="http://yulanguo.me/" target="_blank">Yulan Guo</a></center>*** <br>

### <center><img src="https://raw.github.com/YingqianWang/Flickr1024/master/pics/Flickr1024.jpg" width="480"></center>

***Flickr1024 is a large-scale stereo dataset, which consists of 1024 high-quality images pairs and covers diverse senarios. 
This dataset can be employed for stereo image super-resolution (SR). [<a href="http://openaccess.thecvf.com/content_ICCVW_2019/papers/LCI/Wang_Flickr1024_A_Large-Scale_Dataset_for_Stereo_Image_Super-Resolution_ICCVW_2019_paper.pdf">details</a>]*** <br><br>
***<a href="https://github.com/YingqianWang/Flickr1024">Github Project Page</a>*** <br><br>

## Sample Images

<br><img src="https://raw.github.com/YingqianWang/Flickr1024/master/pics/Sample Images.jpg"><br><br>

## Downloads
* The ***Flickr1024*** dataset can be downloaded via
***<a href="https://pan.baidu.com/s/1YD76gpQ2WjkhjkMnHmU3tQ" target="_blank">Baidu Drive</a>*** or 
***<a href="https://drive.google.com/drive/folders/10LTXCSp9UqY9A9HVj3sAf7zmS4KdJo2T?usp=sharing" target="_blank">Google Drive</a>***

## Notations
* The ***Flickr1024*** dataset is available for ***non-commercial*** use only. 
  Therefore, You agree **NOT** to reproduce, duplicate, copy, sell, trade, or resell any portion of the images and any portion of derived data.
* All images on the ***Flickr1024*** dataset are obtained from ***<a href="https://flickr.com" target="_blank">Flickr</a>***
and they are not the property of our laboratory. 
* We reserve the right to terminate your access to the ***Flickr1024*** dataset at any time.

## Acknowledgement
We would like to thank ***<a href="https://www.flickr.com/photos/stereotron/" target="_blank">Sascha Becher</a>***
 and ***<a href="https://www.flickr.com/photos/tombentz" target="_blank">Tom Bentz</a>*** for the approval of using their cross-eye stereo photographs.

## Citiations
* @InProceedings{flickr1024,<br>
  author = {Wang, Yingqian and Wang, Longguang and Yang, Jungang and An, Wei and Guo, Yulan},<br>
  title = {Flickr1024: A Large-Scale Dataset for Stereo Image Super-Resolution},<br>
  booktitle = {The IEEE International Conference on Computer Vision (ICCV) Workshops},<br>
  month = {Oct},<br>
  year = {2019}<br>
  }<br>
  
* @inproceedings{PASSRnet,<br>
  title={Learning parallax attention for stereo image super-resolution},<br>
  author={Wang, Longguang and Wang, Yingqian and Liang, Zhengfa and Lin, Zaiping and Yang, Jungang and An, Wei and Guo, Yulan},<br>
  booktitle={Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition},<br>
  pages={12250--12259},<br>
  year={2019}<br>
  }<br>


## Related Work
The following works have employed the ***Flickr1024*** dataset:

* A Stereo Attention Module for Stereo Image Super-Resolution, *IEEE Signal Processing Letters*, 2020. **[<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8998204">pdf</a>]**, **[<a href="https://github.com/XinyiYing/SAM">code</a>]**.
* Parallax-based Spatial and Channel Attention for Stereo Image Super-resolution, *IEEE Access*, 2019. **[<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8936066">pdf</a>]**.
* Convolutional Neural Networks: A Binocular Vision Perspective, *arXiv 2019*. **[<a href="https://arxiv.xilesou.top/pdf/1912.10201.pdf">pdf</a>]**
* Learning Parallax Attention for Stereo Image Super-resolution, *CVPR 2019*. **[<a href="https://arxiv.org/pdf/1903.05784.pdf">pdf</a>]**, **[<a href="https://github.com/LongguangWang/PASSRnet">code</a>]**.

## Other Stereo Image Datasets
* ***<a href="https://github.com/YuhuaXu/StereoDataset" target="_blank">The InStereo2K Dataset</a>***
* ***<a href="http://www.cvlibs.net/datasets/kitti/index.php" target="_blank">The KITTI Vision Benchmark Suite</a>***
* ***<a href="http://vision.middlebury.edu/stereo/" target="_blank">The Middlebury Stereo Vision Page</a>***
* ***<a href="https://www.eth3d.net/" target="_blank">The ETH3D Benchmark</a>***


## Contact
Please contact us at ***wangyingqian16@nudt.edu.cn*** for any question.

